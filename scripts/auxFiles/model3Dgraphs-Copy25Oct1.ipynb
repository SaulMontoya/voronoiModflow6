{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flopy is installed in /home/gida2/.local/lib/python3.6/site-packages/flopy\n",
      "loading simulation...\n",
      "  loading simulation name file...\n",
      "  loading tdis package...\n",
      "  loading model gwf6...\n",
      "    loading package disv...\n",
      "    loading package npf...\n",
      "    loading package ic...\n",
      "    loading package rch...\n",
      "    loading package evt...\n",
      "    loading package drn...\n",
      "    loading package oc...\n",
      "  loading ims package model...\n"
     ]
    }
   ],
   "source": [
    "import pyvista as pv\n",
    "import numpy as np\n",
    "import os, flopy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.tri import Triangulation, LinearTriInterpolator\n",
    "from tqdm import tqdm\n",
    "\n",
    "    \n",
    "name = 'Model'\n",
    "workspace = '../model'\n",
    "mf_exe_name = '../exe/mf6'\n",
    "\n",
    "sim = flopy.mf6.MFSimulation.load(sim_name=name, exe_name=mf_exe_name, sim_ws=workspace)\n",
    "\n",
    "mfmodel = sim.get_model(model_name='model')\n",
    "\n",
    "fname = os.path.join(workspace, name + '.hds')\n",
    "hdobj = flopy.utils.HeadFile(fname, precision='double')\n",
    "head = hdobj.get_data()\n",
    "headRshp = head.reshape((head.shape[0],head.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vertex interpolation functions\n",
    "def triInterpolation(zValue, xPoints, yPoints):\n",
    "    triObj = Triangulation(xPoints, yPoints)\n",
    "    fz = LinearTriInterpolator(triObj, zValue)\n",
    "    return fz\n",
    "\n",
    "def interpVerticesZ(zName, zValues, xyCentroid, xyVertices):\n",
    "    interpVerticesList=[]\n",
    "    layTri = triInterpolation(zValues, xyCentroid[:,0], xyCentroid[:,1])\n",
    "    \n",
    "    for index, vertice in tqdm(enumerate(xyVertices), desc=\"Working vertices for %s\"%zName):\n",
    "        \n",
    "        newZ = layTri(vertice[0],vertice[1])\n",
    "        if newZ.mask:\n",
    "            for index2, row2 in enumerate(cell2dList):\n",
    "                if index in row2[1:]:\n",
    "                    newZ = zValues[index2]\n",
    "        interpVerticesList.append(newZ)\n",
    "    interpVerticesArray = np.array(interpVerticesList)\n",
    "    return interpVerticesArray\n",
    "\n",
    "def interpVerticesHeads(zName, zValues, xyCentroid, xyVertices):\n",
    "    interpVerticesList=[]\n",
    "    #filtering over real heads\n",
    "    realHeadIndexArray = (zValues>-1.00000000e+30).nonzero()[0]\n",
    "    #reassigning arrays\n",
    "    zValuesFiltered = zValues[realHeadIndexArray]\n",
    "    xyCentroidFiltered = xyCentroid[realHeadIndexArray]\n",
    "    verticesIndexFiltered = []\n",
    "    for headCell in realHeadIndexArray:\n",
    "        verticesIndexFiltered+=cell2dList[headCell][1:]\n",
    "    verticesIndexFiltered = list(set(verticesIndexFiltered))\n",
    "    #xyVerticesFiltered = xyVertices[cell2dListFiltered]\n",
    "    #print(xyVerticesFiltered)\n",
    "    #filtered triangle interpolation\n",
    "    layTri = triInterpolation(zValuesFiltered, xyCentroidFiltered[:,0], xyCentroidFiltered[:,1])\n",
    "    \n",
    "    interpVerticesArray = np.ones([nvert])*-1.00000000e+30\n",
    "    for vertexIndex in tqdm(verticesIndexFiltered, desc=\"Working vertices for %s\"%zName):\n",
    "        vertice = xyVertices[vertexIndex]\n",
    "        newZ = layTri(vertice[0],vertice[1])\n",
    "        if newZ.mask:\n",
    "            for index2, row2 in enumerate(cell2dList):\n",
    "                if vertexIndex in row2[1:]:\n",
    "                    newZ = zValues[index2]\n",
    "        interpVerticesArray[vertexIndex] = newZ\n",
    "    return interpVerticesArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating vertices Z values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Working vertices for Lay 0: 99154it [00:08, 11835.79it/s]\n",
      "Working vertices for Lay 1: 99154it [00:08, 11530.29it/s]\n",
      "Working vertices for Lay 2: 99154it [00:08, 11562.61it/s]\n",
      "Working vertices for Lay 3: 99154it [00:08, 11560.86it/s]\n",
      "Working vertices for Lay 4: 99154it [00:08, 11697.74it/s]\n",
      "Working vertices for Lay 5: 99154it [00:08, 11514.47it/s]\n",
      "Working vertices for Lay 6: 99154it [00:08, 11625.87it/s]\n",
      "Working vertices for Lay 0:  14%|█▍        | 1745/12171 [00:00<00:00, 17442.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating vertices head values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Working vertices for Lay 0: 100%|██████████| 12171/12171 [00:02<00:00, 4546.54it/s]\n",
      "Working vertices for Lay 1: 100%|██████████| 13460/13460 [00:03<00:00, 4001.19it/s]\n",
      "Working vertices for Lay 2: 100%|██████████| 99154/99154 [00:08<00:00, 12209.17it/s]\n",
      "Working vertices for Lay 3: 100%|██████████| 99154/99154 [00:07<00:00, 12486.14it/s]\n",
      "Working vertices for Lay 4: 100%|██████████| 99154/99154 [00:08<00:00, 12367.82it/s]\n",
      "Working vertices for Lay 5: 100%|██████████| 99154/99154 [00:07<00:00, 12437.77it/s]\n",
      "Working vertices for Lay 6: 100%|██████████| 99154/99154 [00:08<00:00, 12239.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# define model variables from flopy instanes\n",
    "nlay = mfmodel.disv.nlay.array\n",
    "nvert = mfmodel.disv.nvert.array\n",
    "ncpl = mfmodel.disv.ncpl.array\n",
    "modelCellZ = np.vstack((mfmodel.disv.top.array,mfmodel.disv.botm.array)) #cell Z in all layers\n",
    "modelHeadZ = np.vstack([headRshp,headRshp[-1]])\n",
    "# XY array for all cellvertices and centroids\n",
    "verticesXYArray = np.dstack((mfmodel.disv.vertices.array.xv,mfmodel.disv.vertices.array.yv))[0] \n",
    "centroidXYArray = np.dstack((mfmodel.disv.cell2d.array.xc,mfmodel.disv.cell2d.array.yc))[0]\n",
    "# XYZ for cell centroid\n",
    "#centroidXYZArray = np.zeros((nlay,ncpl))\n",
    "centroidXYZDict = {}\n",
    "for lay in range(nlay):\n",
    "    centroidXYZDict[str(lay)] = np.dstack((mfmodel.disv.cell2d.array.xc,mfmodel.disv.cell2d.array.yc,(modelCellZ[lay] + modelCellZ[lay+1])/2))[0]\n",
    "#centroidXYZArray = np.dstack((mfmodel.disv.cell2d.array.xc,mfmodel.disv.cell2d.array.yc,centroidZArray))[0]\n",
    "\n",
    "cell2dList = []\n",
    "for index, cell in enumerate(mfmodel.disv.cell2d.array):\n",
    "    vertexIndexList = [x for x in list(cell)[3:] if x is not None]\n",
    "    cell2dList.append(vertexIndexList)        \n",
    "    \n",
    "# calculate cell vertex Z\n",
    "print('Calculating vertices Z values')\n",
    "modelVertZ = np.zeros((nlay+1,nvert))\n",
    "for i in range(nlay+1):\n",
    "    modelVertZ[i] = interpVerticesZ('Lay '+str(i),modelCellZ[i], centroidXYArray, verticesXYArray)\n",
    "    \n",
    "# calculate cell vertex head\n",
    "print('Calculating vertices head values')\n",
    "modelVertHead = np.zeros((nlay+1,nvert))\n",
    "for i in range(nlay+1):\n",
    "    modelVertHead[i] = interpVerticesHeads('Lay '+str(i),modelHeadZ[i], centroidXYArray, verticesXYArray)\n",
    "    \n",
    "cell2dArray = np.hstack(cell2dList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for model geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Working geometries for model grid: 100%|██████████| 6/6 [00:24<00:00,  4.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on the outer model shell\n"
     ]
    }
   ],
   "source": [
    "baseGridXYZ = np.hstack((verticesXYArray,np.zeros([nvert,1])))\n",
    "baseGrid = pv.PolyData(baseGridXYZ,cell2dArray)\n",
    "\n",
    "layerTubes = {}\n",
    "for lay in tqdm(range(nlay),desc=(\"Working geometries for model grid\")):\n",
    "    workingGrid = baseGrid.copy()\n",
    "    workingVolume = workingGrid.extrude([0,0,1])\n",
    "    for vert in range(nvert):\n",
    "        workingVolume.points[vert][2] = modelVertZ[lay,vert]\n",
    "        workingVolume.points[vert+nvert][2] = modelVertZ[lay+1,vert]\n",
    "    layerTubes[str(lay)] = workingVolume\n",
    "layerBlocks = pv.MultiBlock(layerTubes)\n",
    "totalModelGrid = layerBlocks.combine()\n",
    "totalModelGrid.save('../vtk/totalModelGrid.vtk')\n",
    "\n",
    "print('Working on the outer model shell')\n",
    "workingGrid = baseGrid.copy()\n",
    "workingVolume = workingGrid.extrude([0,0,1])\n",
    "for vert in range(nvert):\n",
    "    workingVolume.points[vert][2] = modelVertZ[0,vert]\n",
    "    workingVolume.points[vert+nvert][2] = modelVertZ[nlay,vert]\n",
    "workingVolume.save('../vtk/modelOuterShell.vtk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Working head cell for model grid: 100%|██████████| 6/6 [00:23<00:00,  3.92s/it]\n"
     ]
    }
   ],
   "source": [
    "layerTubes = {}\n",
    "for lay in tqdm(range(nlay),desc=(\"Working head cell for model grid\")):\n",
    "    workingGrid = baseGrid.copy()\n",
    "    #filtering cell heads\n",
    "    layCellHeads = headRshp[lay]\n",
    "    #layCellHeads[layCellHeads == -1.00000000e+30] = np.nan\n",
    "\n",
    "    #for cell in range(ncpl):\n",
    "    workingGrid.cell_arrays['cellHead']=layCellHeads\n",
    "    workingVolume = workingGrid.extrude([0,0,1])\n",
    "    for vert in range(nvert):\n",
    "        workingVolume.points[vert][2] = modelVertZ[lay,vert]\n",
    "        workingVolume.points[vert+nvert][2] = modelVertZ[lay+1,vert]\n",
    "    workingVolume.point_arrays['vertexHead']=np.hstack([modelVertHead[lay],modelVertHead[lay+1]])\n",
    "    workingVolume = workingVolume.threshold(value=-1.00000000e+30, scalars='cellHead')\n",
    "    layerTubes[str(lay)] = workingVolume\n",
    "layerBlocks = pv.MultiBlock(layerTubes)\n",
    "totalModelGrid = layerBlocks.combine()\n",
    "totalModelGrid.save('../vtk/totalModelHeads.vtk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#head.shape\n",
    "#centroidXYZArray.shape\n",
    "#centroidHeads = pv.PolyData(centroidXYZArray)\n",
    "#centroidHeads.point_arrays['head'] = headRshp.flatten()\n",
    "#centroidHeads = centroidHeads(value=-1.00000000e+30, scalars='head')\n",
    "#centroidHeads.save('../vtk/centroidHeads.vtk')\n",
    "#centroidHeads.point_arrays?\n",
    "#centroidXYZArray\n",
    "layerTubes = {}\n",
    "for lay in range(nlay):\n",
    "    workingPCloud = pv.PolyData(centroidXYZDict[str(lay)])\n",
    "    workingPCloud.point_arrays['head']=headRshp[lay]\n",
    "    workingPCloud = workingPCloud.threshold(value=-1.00000000e+30, scalars='head')\n",
    "    layerTubes[str(lay)]= workingPCloud\n",
    "layerBlocks = pv.MultiBlock(layerTubes)\n",
    "totalPCloud = layerBlocks.combine()\n",
    "totalPCloud.save('../vtk/totalPCloud.vtk')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "layerTubes = {}\n",
    "for lay in tqdm(range(nlay),desc=(\"Working head cell for model grid\")):\n",
    "    workingGrid = baseGrid.copy()\n",
    "    #filtering head cells\n",
    "    layCellHeads = head[lay][0]\n",
    "    layCellHeads[layCellHeads == -1.00000000e+30] = np.nan\n",
    "    \n",
    "    for cell in range(ncpl):\n",
    "        workingGrid.cell_arrays['head']=layCellHeads\n",
    "    workingVolume = workingGrid.extrude([0,0,1])\n",
    "    for vert in range(nvert):\n",
    "        workingVolume.points[vert][2] = modelVertZ[lay,vert]\n",
    "        workingVolume.points[vert+nvert][2] = modelVertZ[lay+1,vert]\n",
    "\n",
    "    layerTubes[str(lay)] = workingVolume\n",
    "layerBlocks = pv.MultiBlock(layerTubes)\n",
    "totalModelGrid = layerBlocks.combine()\n",
    "totalModelGrid.save('../vtk/totalModelHeads.vtk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workingGrid = baseGrid.copy()\n",
    "workingGrid.points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalModelGrid = layerBlocks.combine(merge_points=True)\n",
    "totalModelGrid.points.shape[0]-99154*7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for cell heads"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "cellTubes = {}\n",
    "for index, cell in tqdm(enumerate(mfmodel.disv.cell2d.array)):\n",
    "    vertexIndexList = [x for x in list(cell)[4:] if x is not None]\n",
    "    filterVertexIndexList = [len(vertexIndexList)] + list(range(len(vertexIndexList)))\n",
    "    filterVertexIndexArray = np.array(filterVertexIndexList)\n",
    "    #create polydata for lay\n",
    "    layerTubes = {}\n",
    "    for lay in range(nlay):\n",
    "        if head[lay][0][index] > -1.00000000e+30:\n",
    "            filterVertexArray = np.array([list(verticesXYArray[vertex]) + [modelVertZ[lay,vertex]] for vertex in vertexIndexList])\n",
    "            cellSurf = pv.PolyData(filterVertexArray, filterVertexIndexArray)\n",
    "            cellSurf.cell_arrays['head'] = headRshp[lay,index]\n",
    "            cellZ = modelCellZ[:,index]\n",
    "            cellMesh = cellSurf.extrude([0, 0, cellZ[lay+1]-cellZ[lay]])\n",
    "            layerTubes[str(lay)] = cellMesh \n",
    "    blocks = pv.MultiBlock(layerTubes)\n",
    "    cellTubes[str(index)] = blocks.combine()\n",
    "totalModelCells = pv.MultiBlock(cellTubes)\n",
    "totalModelMerged = totalModelCells.combine()\n",
    "totalModelMerged.save('../vtk/modelCellHeads.vtk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for water table"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "wtCellList =[] \n",
    "for index in tqdm(range(ncpl)):\n",
    "    headCell = headRshp[:,index]\n",
    "    wtCell = headCell[headCell>-1.00000000e+30][0]\n",
    "    wtCellList.append(wtCell)\n",
    "wtCellList = interpVertices(wtCellList, centroidXYArray, verticesXYArray)\n",
    "wtCellList"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "cellTubesList = []\n",
    "cellTubesDict = {}\n",
    "#cellX = pv.PolyData()\n",
    "for index, cell in tqdm(enumerate(mfmodel.disv.cell2d.array)):\n",
    "    vertexIndexList = [x for x in list(cell)[4:] if x is not None]\n",
    "    filterVertexIndexList = [len(vertexIndexList)] + list(range(len(vertexIndexList)))\n",
    "    filterVertexIndexArray = np.array(filterVertexIndexList)\n",
    "    #create polydata for lay\n",
    "    filterVertexArray = np.array([list(verticesXYArray[vertex]) + [wtCellList[vertex]] for vertex in vertexIndexList])\n",
    "    cellSurf = pv.PolyData(filterVertexArray, filterVertexIndexArray)\n",
    "    #cellSurf.cell_arrays['watertable'] = wtCellList[index]\n",
    "    cellTubesList.append(cellSurf)\n",
    "    #cellX += cellSurf\n",
    "    \n",
    "for index, cell in enumerate(cellTubesList):\n",
    "    cellTubesDict[str(index)]=cell\n",
    "    \n",
    "totalModelCells = pv.MultiBlock(cellTubesDict)\n",
    "totalModelMerged = totalModelCells.combine()\n",
    "totalModelMerged.save('../vtk/modelWaterTable.vtk')\n",
    "#cellX.save('../vtk/modelWaterTable.vtk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for drain boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "drnPkg = mfmodel.get_package('drn_0')\n",
    "drainTubes = {}\n",
    "for index, drnCell in tqdm(enumerate(drnPkg.stress_period_data.array[0])):\n",
    "    cellNumber = drnCell[0][1]\n",
    "    cellLay = drnCell[0][0]\n",
    "    cellGrid = mfmodel.disv.cell2d.array[cellNumber]\n",
    "    vertexIndexList = [x for x in list(cellGrid)[4:] if x is not None]\n",
    "    filterVertexIndexList = [len(vertexIndexList)] + list(range(len(vertexIndexList)))\n",
    "    filterVertexIndexArray = np.array(filterVertexIndexList)\n",
    "    filterVertexArray = np.array([list(verticesXYArray[vertex]) + [modelCellZ[cellLay,cellNumber]] for vertex in vertexIndexList])\n",
    "    cellSurf = pv.PolyData(filterVertexArray, filterVertexIndexArray)\n",
    "    cellSurf.cell_arrays['elevation'] = drnCell[1]\n",
    "    cellSurf.cell_arrays['cond'] = drnCell[2]\n",
    "    cellZ = modelCellZ[:,cellNumber]\n",
    "    cellMesh = cellSurf.extrude([0, 0, cellZ[cellLay +1]-cellZ[cellLay]])\n",
    "    drainTubes[str(index)] = cellMesh \n",
    "totalDrainsCells = pv.MultiBlock(drainTubes)\n",
    "totalDrainsMerged = totalDrainsCells.combine()\n",
    "totalDrainsMerged.save('../vtk/modelDrains.vtk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "import numpy as np\n",
    "import os, flopy\n",
    "import matplotlib.pyplot as plt\n",
    "name = 'Model'\n",
    "workspace = '../model'\n",
    "mf_exe_name = '../exe/mf6'\n",
    "\n",
    "sim = flopy.mf6.MFSimulation.load(sim_name=name, exe_name=mf_exe_name, sim_ws=workspace)\n",
    "\n",
    "mfmodel = sim.get_model(model_name='model')\n",
    "\n",
    "fname = os.path.join(workspace, name + '.hds')\n",
    "hdobj = flopy.utils.HeadFile(fname, precision='double')\n",
    "head = hdobj.get_data()\n",
    "headRshp = head.reshape((head.shape[0],head.shape[2]))\n",
    "\n",
    "mtop = np.ones([mfmodel.disv.nvert.array ])*mfmodel.disv.top[0]\n",
    "verticesXYArray = np.dstack((mfmodel.disv.vertices.array.xv,mfmodel.disv.vertices.array.yv))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelz = np.vstack((mfmodel.disv.top.array,mfmodel.disv.botm.array))\n",
    "nlay = mfmodel.disv.nlay.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellSurf = pv.PolyData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
